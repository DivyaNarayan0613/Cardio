# -*- coding: utf-8 -*-
"""CardioVascularDisease.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lHB--1NJ3qX4SHIZ-1YpRAgLP316DP_K

This dataset provides information on the risk factors for
heart disease. The original database contains 76 attributes, but all published experiments refer to using a subset of 14 of thema and is refferenced as Cleveland dataset (link).
Experiments with the Cleveland database have concentrated on attempting to distinguish presence (value 1) or absence (value 0) of heart disease in the patient.
This is a typical binary classification task.

This database contains attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to this date.The "goal" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence from absence (value 0).

Source: https://archive.ics.uci.edu/ml/datasets/Heart+Disease

Creators:

    Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
    University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
    University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
    V.A. Medical Center, Long Beach and Cleveland Clinic Foundation: Robert Detrano, M.D., Ph.D.

Donor: David W. Aha (aha '@' ics.uci.edu) (714) 856-8779
"""

import numpy as np
import pandas as pd

from google.colab import files
uploaded=files.upload()

df=pd.read_csv('CardioVascularDisease.csv')

df.describe()

"""**Attribute Information**
    Age: Age
    Sex: Sex (1 = male; 0 = female)
        ChestPain: Chest pain (typical, asymptotic, nonanginal, nontypical)
    RestBP: Resting blood pressure
        Chol: Serum cholestoral in mg/dl
        Fbs: Fasting blood sugar > 120 mg/dl (1 = true; 0 = false)
        RestECG: Resting electrocardiographic results
        MaxHR: Maximum heart rate achieved
        ExAng: Exercise induced angina (1 = yes; 0 = no)
        Oldpeak: ST depression induced by exercise relative to rest
        Slope: Slope of the peak exercise ST segment
        Ca: Number of major vessels colored by flourosopy (0 - 3)
        Thal: (3 = normal; 6 = fixed defect; 7 = reversable defect)
        target: AHD - Diagnosis of heart disease (1 = yes; 0 = no)

"""

df.info()

import matplotlib.pyplot as plt
df.hist(bins=50, figsize=(20,15))
plt.show()

corr_matrix=df.corr()
corr_matrix["cp"].sort_values(ascending=True)

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize=(7,5)) 
sns.heatmap(corr_matrix,annot=True,cmap='RdYlGn_r') 
plt.show()

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'cp', y = 'target', data = df)

sns.distplot(x['cp']);          #Similarly this curve fitting can be verified for other attributes

x=df.drop(['target'],axis=1)
y=df['target']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

print(x)

print(y)

from sklearn import metrics
from sklearn.model_selection import cross_val_score
def cross_val(model):
  pred = cross_val_score(model, x, y, cv=10)
  return pred.mean()

def print_evaluate(true, predicted):  
    mae = metrics.mean_absolute_error(true, predicted)
    mse = metrics.mean_squared_error(true, predicted)
    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))
    r2_square = metrics.r2_score(true, predicted)
    print('MAE:', mae)
    print('MSE:', mse)
    print('RMSE:', rmse)
    print('R2 Square', r2_square)
    
def evaluate(true, predicted):
    mae = metrics.mean_absolute_error(true, predicted)
    mse = metrics.mean_squared_error(true, predicted)
    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))
    r2_square = metrics.r2_score(true, predicted)
    return mae, mse, rmse, r2_square

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('std_scalar', StandardScaler())
])

x_train = pipeline.fit_transform(x_train)
x_test = pipeline.transform(x_test)

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression(normalize=True)
lin_reg.fit(x_train,y_train)

# print the intercept
print(lin_reg.intercept_)

coeff_df = pd.DataFrame(lin_reg.coef_, x.columns, columns=['Coefficient'])
coeff_df

pred = lin_reg.predict(x_test)

plt.scatter(y_test, pred)

sns.distplot((y_test - pred), bins=50);

train_pred = lin_reg.predict(x_train)
test_pred = lin_reg.predict(x_test)

print('Test set evaluation:\n_____________________________________')
print_evaluate(y_test, test_pred)
print('====================================')
print('Train set evaluation:\n_____________________________________')
print_evaluate(y_train, train_pred)

results_df = pd.DataFrame(data=[["Linear Regression", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], 
                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', "Cross Validation"])
results_df

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
svm=SVC()
svm.fit(x_train, y_train)
pred = svm.predict(x_test)
print(accuracy_score(y_test, pred))
print(confusion_matrix(y_test, pred))
print(classification_report(y_test, pred))

